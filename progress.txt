## 2026-01-19: Implemented tasks/ folder management functions

### Completed Task: Create tasks/ folder management functions

Added comprehensive functions to `ralphy.sh` for managing task files in the `tasks/` folder:

**Core Functions:**
- `init_tasks_folder()` - Creates tasks/ folder if it doesn't exist
- `get_next_task_number()` - Generates sequential 3-digit task numbers (001, 002, etc.)
- `slugify_task_name()` - Converts task names to filename-safe slugs
- `create_task_file()` - Creates new task files with the PRD-specified template
- `get_task_file()` - Finds task file by number, handling status prefixes
- `parse_task_field()` - Extracts fields (status, next_agent, task_name, task_number)
- `get_task_status()` - Gets task status by task number
- `update_task_field()` - Updates status or next_agent fields
- `update_subtask_status()` - Updates subtask status and attempt counts
- `rename_task_with_status()` - Adds/removes status prefixes like [Needs-Human]
- `list_task_files()` - Lists all task files sorted by number
- `get_next_pending_task_file()` - Gets next actionable task
- `count_tasks_by_status()` - Counts tasks by status type
- `enforce_task_line_limit()` - Enforces 150-line limit on task files
- `check_waiting_tasks()` - Unblocks tasks waiting on a completed task

**Task File Format:**
```markdown
# Task 001: [Name]
## Status: In Progress | Needs-Human | Waiting on Task X | Complete
## Next Agent: research | implement | test-typecheck | test-terminal | test-browser | test-automated

### Research — Status: Pending | Attempts: 0/5
### Implementation — Status: Pending | Attempts: 0/5
### Test: Type Check — Status: Pending | Attempts: 0/5
### Test: Terminal Errors — Status: Pending | Attempts: 0/5
### Test: Browser — Status: Pending | Attempts: 0/5
### Test: Automated (Playwright) — Status: Pending | Attempts: 0/5
```

**Testing:**
- Created comprehensive test suite in `test_tasks_folder.sh`
- 48 tests covering all functions
- All tests pass

## 2026-01-19: Created prompts/research.txt with Context7 MCP instructions

### Completed Tasks:
1. **Implement task file CRUD** - Confirmed already complete (was implemented alongside tasks/ folder management)
2. **Create prompts/research.txt** - Created Research Agent prompt

**prompts/research.txt Features:**
- Template placeholders: `{{TASK_FILE}}`, `{{TASK_NAME}}`
- Codebase exploration instructions (search patterns, find related files)
- Context7 MCP usage examples for external library documentation:
  - `resolve-library-id` to find library IDs
  - `query-docs` to fetch documentation
- Output requirements (update task file Research section, set Next Agent to "implement")
- Clear rules: NO implementation code, only gather and document information

**Testing:**
- Created `test_prompts.sh` with 18 tests for prompt files
- Tests verify: file existence, required placeholders, Context7 instructions, output requirements
- All 66 tests pass (48 task folder + 18 prompt tests)

## 2026-01-19: Created prompts/implement.txt with reasoning documentation

### Completed Task: Create prompts/implement.txt (document reasoning, not just changes)

**prompts/implement.txt Features:**
- Template placeholders: `{{TASK_FILE}}`, `{{TASK_NAME}}`
- Instructions to read Research section first before coding
- Requirements for documenting reasoning:
  - Approach chosen
  - Alternatives considered
  - Why this approach was selected
  - Key decisions made
  - Files changed
- Output requirements (update task file Implementation section, set Next Agent to "test-typecheck")
- Failure handling (5 attempts, Needs-Human marking)
- Clear rules: follow patterns from research, keep changes focused, don't over-engineer

**Testing:**
- Added 10 new tests to `test_prompts.sh` for implement.txt
- Tests verify: file existence, placeholders, reasoning requirements, output requirements, research reading, failure handling
- All 79 tests pass (48 task folder + 31 prompt tests)

## 2026-01-19: Created prompts/test-typecheck.txt

### Completed Task: Create prompts/test-typecheck.txt

**prompts/test-typecheck.txt Features:**
- Template placeholders: `{{TASK_FILE}}`, `{{TASK_NAME}}`
- Instructions to run `tsc --noEmit` or project's configured type check command
- Auto-detection of type check commands from package.json scripts
- Instructions to analyze and fix type errors introduced by implementation
- References Implementation section to understand what was changed
- Output requirements (update task file Test: Type Check section, set Next Agent to "test-terminal")
- Failure handling (5 attempts, Needs-Human marking)
- Clear rules: fix type errors, don't modify logic; if logic changes needed, go back to implement

**Testing:**
- Added 11 new tests to `test_prompts.sh` for test-typecheck.txt
- Tests verify: file existence, placeholders, tsc command, output requirements, failure handling, auto-detect instructions, implementation reference
- All 91 tests pass (48 task folder + 43 prompt tests)

## 2026-01-19: Created prompts/test-terminal.txt

### Completed Task: Create prompts/test-terminal.txt (start dev server, check errors)

**prompts/test-terminal.txt Features:**
- Template placeholders: `{{TASK_FILE}}`, `{{TASK_NAME}}`
- Instructions to start and monitor the dev server
- Auto-detection of dev server commands from package.json scripts (dev, start, serve, develop)
- Instructions to check for compile and runtime errors
- References Implementation section to understand what was changed
- Output requirements (update task file Test: Terminal Errors section, set Next Agent to "test-browser")
- Failure handling (5 attempts, Needs-Human marking)
- Timeout handling guidance (30 seconds for server startup)
- Clear rules: fix errors, don't modify logic; if logic changes needed, go back to implement

**Testing:**
- Added 11 new tests to `test_prompts.sh` for test-terminal.txt
- Tests verify: file existence, placeholders, dev server instructions, output requirements, failure handling, auto-detect instructions, implementation reference, error types
- All 106 tests pass (48 task folder + 58 prompt tests)

## 2026-01-19: Created prompts/test-browser.txt

### Completed Task: Create prompts/test-browser.txt (start server, test functionality via --chrome)

**prompts/test-browser.txt Features:**
- Template placeholders: `{{TASK_FILE}}`, `{{TASK_NAME}}`
- Instructions to start and manage its own dev server instance
- Browser automation instructions using --chrome mode
- Feature testing guidelines:
  - Navigate to relevant pages
  - Test user interactions (clicks, forms, etc.)
  - Verify visual elements render correctly
  - Check browser console for JavaScript errors
- References Research and Implementation sections for context
- Output requirements (update task file Test: Browser section, set Next Agent to "test-automated")
- Failure handling (5 attempts, Needs-Human marking)
- Auto-detection of dev server commands from package.json
- Server lifecycle management (start, wait for ready, test, stop)
- Common issues checklist: broken imports, missing APIs, routing, state management, CSS issues

**Testing:**
- Added 14 new tests to `test_prompts.sh` for test-browser.txt
- Tests verify: file existence, placeholders, --chrome reference, dev server instructions, output requirements, failure handling, console checking, auto-detect instructions, own server emphasis
- All 125 tests pass (48 task folder + 77 prompt tests)

## 2026-01-19: Created prompts/test-automated.txt

### Completed Task: Create prompts/test-automated.txt (write Playwright tests, then run)

**prompts/test-automated.txt Features:**
- Template placeholders: `{{TASK_FILE}}`, `{{TASK_NAME}}`
- Instructions to analyze feature from Research and Implementation sections
- Playwright test writing guidelines:
  - Create test files in project's test directory
  - Follow existing test patterns in codebase
  - Cover happy path scenarios
  - Cover edge cases and error states
  - Use descriptive test names
- Test execution instructions:
  - Run `npx playwright test` or project's configured command
  - Auto-detect test commands from package.json scripts
  - Analyze and fix test failures
- Output requirements:
  - Update Test: Automated (Playwright) section
  - Set task Status to "Complete" when all tests pass
  - Set Next Agent to "none" (final step in workflow)
- Failure handling (5 attempts, Needs-Human marking)
- Test writing patterns with example code
- Common assertions reference

**Testing:**
- Added 17 new tests to `test_prompts.sh` for test-automated.txt
- Tests verify: file existence, placeholders, Playwright instructions, write tests instructions, output requirements, failure handling, auto-detect, test patterns, scenarios coverage, final step handling
- All 148 tests pass (48 task folder + 100 prompt tests)

## 2026-01-19: Implemented 6 agent runner functions

### Completed Task: Implement 6 agent runner functions that read/update task files

Added comprehensive agent runner functions to `ralphy.sh` for running specialized agents:

**Core Functions:**
- `get_subtask_attempts()` - Get current attempt count for a subtask
- `prepare_prompt()` - Load and substitute placeholders in prompt files
- `run_agent()` - Core function to run any agent type with proper state management
- `run_research_agent()` - Run the research agent
- `run_implement_agent()` - Run the implementation agent
- `run_typecheck_agent()` - Run the type check agent
- `run_terminal_agent()` - Run the terminal error agent
- `run_browser_agent()` - Run the browser agent
- `run_automated_agent()` - Run the automated test agent
- `dispatch_agent()` - Dispatch to appropriate agent based on next_agent field
- `mark_task_needs_human()` - Mark task as needing human intervention

**Agent Workflow:**
- Each agent reads task file and extracts task info
- Loads corresponding prompt from prompts/ folder
- Substitutes {{TASK_FILE}} and {{TASK_NAME}} placeholders
- Updates subtask status to "In Progress" with incremented attempts
- Runs AI with prepared prompt
- AI updates task file with results and sets next_agent
- Enforces 150-line limit on task files
- Handles completion, needs-human, and failure states

**Agent Type Mapping:**
| Agent Type | Prompt File | Subtask Name | Next on Success |
|------------|-------------|--------------|-----------------|
| research | research.txt | Research | implement |
| implement | implement.txt | Implementation | test-typecheck |
| test-typecheck | test-typecheck.txt | Test: Type Check | test-terminal |
| test-terminal | test-terminal.txt | Test: Terminal Errors | test-browser |
| test-browser | test-browser.txt | Test: Browser | test-automated |
| test-automated | test-automated.txt | Test: Automated (Playwright) | none (complete) |

**Testing:**
- Created comprehensive test suite in `test_agent_runners.sh`
- 53 tests covering all agent runner functions
- All 201 tests pass (48 task folder + 100 prompt + 53 agent runner)

## 2026-01-19: Each agent outputs Next Agent field for loop to follow

### Completed Task: Each agent outputs Next Agent field for loop to follow

Enhanced all 6 agent prompts with explicit "Next Agent field rules" to ensure agents consistently output the correct Next Agent value for the main loop to follow.

**Changes to prompts/research.txt:**
- Added "Next Agent field rules" section with explicit rules:
  - On SUCCESS: Set `## Next Agent: implement`
  - On FAILURE: Set `## Next Agent: research` (to retry)
  - On BLOCKED: Set `## Next Agent: none` and `## Status: Needs-Human`
- Added "Always update these fields" checklist

**Changes to prompts/implement.txt:**
- Added "Next Agent field rules" section:
  - On SUCCESS: Set `## Next Agent: test-typecheck`
  - On FAILURE: Set `## Next Agent: research`
  - On BLOCKED: Set `## Next Agent: none` and `## Status: Needs-Human`

**Changes to prompts/test-typecheck.txt:**
- Added "Next Agent field rules" section:
  - On SUCCESS: Set `## Next Agent: test-terminal`
  - On FAILURE: Set `## Next Agent: implement`
  - On BLOCKED: Set `## Next Agent: none` and `## Status: Needs-Human`
- Added "Status update rules" for clarity

**Changes to prompts/test-terminal.txt:**
- Added "Next Agent field rules" section:
  - On SUCCESS: Set `## Next Agent: test-browser`
  - On FAILURE: Set `## Next Agent: implement`
  - On BLOCKED: Set `## Next Agent: none` and `## Status: Needs-Human`

**Changes to prompts/test-browser.txt:**
- Added "Next Agent field rules" section:
  - On SUCCESS: Set `## Next Agent: test-automated`
  - On FAILURE: Set `## Next Agent: implement`
  - On BLOCKED: Set `## Next Agent: none` and `## Status: Needs-Human`

**Changes to prompts/test-automated.txt:**
- Added "Next Agent field rules" section:
  - On SUCCESS: Set `## Next Agent: none` AND `## Status: Complete`
  - On FAILURE: Set `## Next Agent: implement`
  - On BLOCKED: Set `## Next Agent: none` and `## Status: Needs-Human`

**Testing:**
- Added 24 new tests to `test_prompts.sh` (4 tests per prompt × 6 prompts)
- Tests verify: "Next Agent field rules" section exists, success/failure/blocked rules present
- All 124 prompt tests pass
